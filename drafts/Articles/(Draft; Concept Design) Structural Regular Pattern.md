* (remark) (This part is confusing with those terms, consider saving this only to myself, so put somewhere else) This is an ambitious project, and it will be very useful when it's done. And it should focus as a command line utility. This is NOT (regular approach of) NLP. This can be considered part of SIS.
* (concept, summary, terminology, specification) SRP is divided into multiple steps (in terms of processing) and multiple stages (in terms of definition). The entire SRP can be provided inside a single C# library instead of as some sort of standalone package or scriptable environment to avoid unnecessary burden - if further interfacing is needed, consider develop as seperate programs.
	- (steps) From the program's perspective, there are 4 steps: 1) A given **document** is tokenized by associating **marks and attributes**/tokens with **spans** of texts in a sequential order, if there are any spans not recognized, it's marked `<null>`. A special token is reserved and named `<empty>` for non-semantically relevant empty spaces, which will be stripped out after tokenization. 2) The tokens go through an ordered list of **patterns** and try to find the longest pattern that matches it, this has three **modes** - in **strict mode** the **whole document** must be an exact match to 1 pattern, in **loose mode** the provided document can multiple patterns in a sequential order but no `<null>` or unmatched parts is accepted, in **casual mode** all `<null>` tokens are discarded and the document can match either 1 or multiple or no patterns at all and not all texts need to be matched (i.e. can have remainders). 3) Particular patterns have associated actions, when those patterns are matched, actions are fired. A single document will created a single **session**, all fired events shall share the context within that session. 4) The program shall continue to match more documents either in a sequential or parallel manner, each session is independent of each other but they can have sequantial dependence on consequences of each other to form workflows.
	- (stages) From a user's perspective: 1) The user needs to define **tokenization**, i.e. a dictionary of **words** to tokens. 2) The user needs to define **patterns**, patterns are sequence of tokens and are named, supporting recursion and referencing sub-pattern along with other constructs (try not to introduce confusing; By all means, we might not need sub-patterns, if we just define the patterns in-place, or treat sub-pattern as a preprocessing stage; Written directly as regular expression); patterns **have no orders** and when two patterns both match (i.e. the order they are defined don't match), the longer matched pattern with more specific/sophisticated rules is fired. 3) The user define actions to take when patterns are matched, with optional effects on a shared **session** object. In a purely programming environment, those steps are strongly typed instead of relying on textual definitions.
	- (remark) Notice the elevated clarity and simplicity compared with pure regular expression is: 1) Triggerable events, 2) Named tokens supporting long lists for large vocabulary, 3) Modularization.
	- (remark) Known limitation: this library cannot be used to define a programming language efficiently, because keywords like variable and function names (thus tokens) in a programming langauge isn't known at design time - the only way to work around it is to define patterns to capture those and achieve such matching capability inside patterns. Also notice in current revision, "everything" isn't a valid token content (so this draft differs from original SRP).
	- (example) For KMD format: 1) Tokens: `* ` as starter, `\n` as ender, `\t` as level; 2) Patterns: `(<level>)*<starter>(<null>)*<ender>` for any item (parent hierarchy assembled in triggered action). 2) The `(<null>*)` part shall be further processed for item content: `(` as tag starter, `)` as tag ender, `<tag starter>(<null>)*<tag ender>(<null>)*` for item tags and content. 3) For the tag part we can also further have: `, ` as tag delimiter, `(<null>)+(?:<tag delimiter>(<null>)+)*` for tags.